{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as pl\n",
    "from os.path import join, split, splitext\n",
    "from pypllon.parsers import parse_ctx, load_complex_array\n",
    "from glob import glob\n",
    "from tools.plot import imsshow\n",
    "\n",
    "import os\n",
    "try:\n",
    "    ID = os.environ['ID']\n",
    "    BASEDIR = os.environ['BASEDIR']\n",
    "except KeyError:\n",
    "    ID = 'M3Fou'\n",
    "    BASEDIR = '/Users/dsuess/Downloads/Phaselift_2017_13_3/3x3 phaselift/'\n",
    "   \n",
    "print(ID, '\\n', BASEDIR,'\\n')\n",
    "DIM = int(ID[1])\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# labels of the detectors used\n",
    "DETECTORS_ALL = ['AH', 'BH', 'CH', 'DH', 'EH', 'FH']\n",
    "DETECTORS = DETECTORS_ALL[1:1 + DIM]\n",
    "# id of the experiment\n",
    "outfile = h5py.File('{}.h5'.format(ID), 'a')\n",
    "try:\n",
    "    del outfile['RECR']\n",
    "except KeyError:\n",
    "    pass\n",
    "f = outfile.create_group('RECR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# General information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_git_revision_hash():\n",
    "    return subprocess.check_output(['git', 'rev-parse', 'HEAD']).split()[0]\n",
    "\n",
    "f.attrs['COMMITID'] = get_git_revision_hash()\n",
    "f.attrs['DETECTORS'] = [s.encode() for s in DETECTORS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Preparation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The matrix to be recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# gauss or RECR doesn't matter for this\n",
    "targetfile = BASEDIR + '/Unitaries/%s.dat' % ID\n",
    "target = load_complex_array(targetfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imsshow([target.real, target.imag, np.abs(target)])\n",
    "f['TARGET'] = target\n",
    "f['TARGETFILE'] = targetfile\n",
    "outfile.flush()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_pvecs(fnames, prepvecs):\n",
    "    for fname in fnames:\n",
    "        vecid = split(splitext(fname)[0])[1]\n",
    "        prepvecs[vecid] = load_complex_array(fname)\n",
    "        prepvecs[vecid].attrs['FILE'] = fname\n",
    "\n",
    "    outfile.flush()\n",
    "    \n",
    "fnames = glob(BASEDIR + '/Vectors/VRad%i_*.dat' % DIM)\n",
    "prepvecs = f.create_group('PREPVECS')\n",
    "print(\"Number of RECR preparation vectors: %i\" % len(fnames))\n",
    "load_pvecs(fnames, prepvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Phaselift Raw Measurement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_deteff(fname):\n",
    "    summarydict = parse_ctx(fname)\n",
    "    return  np.array([summarydict['det_eff'][det] for det in DETECTORS])\n",
    "\n",
    "def dict_to_rates(dic):\n",
    "    return np.array([dic.get(det.lower(), 0) for det in DETECTORS])\n",
    "\n",
    "def load_counts(fname):\n",
    "    summarydict = parse_ctx(fname)\n",
    "    rates = np.array([summarydict[det] for det in DETECTORS])\n",
    "\n",
    "    parent = summarydict['metadata']['parent']\n",
    "    path_to_raw = join(split(fname)[0], '..', 'raw', parent + '.ctx')\n",
    "    \n",
    "    try:\n",
    "        c = parse_ctx(path_to_raw)\n",
    "        raw_rates = np.array([dict_to_rates(val) \n",
    "                              for key, val in c.items()\n",
    "                              if key.startswith('count_rates')])\n",
    "\n",
    "        assert np.all(np.sum(raw_rates, axis=0) == rates)\n",
    "        return raw_rates, path_to_raw\n",
    "    except FileNotFoundError:\n",
    "        return rates[None, :], fname\n",
    "\n",
    "def vector_to_counts(globpatt):\n",
    "    matches = glob(globpatt)\n",
    "    if len(matches) != 1:\n",
    "        raise IOError(\"Wrong number of matches %i\" % len(matches))\n",
    "    return load_counts(matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "deteff_file = BASEDIR + '/data/det_eff/det_eff.txt'\n",
    "\n",
    "deteff_all = {name: value \n",
    "              for name, value in zip(DETECTORS_ALL, np.loadtxt(deteff_file))}\n",
    "deteff = np.array([deteff_all[key] for key in DETECTORS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rawcounts = f.create_group('RAWCOUNTS')\n",
    "for pvec in f['PREPVECS'].keys():\n",
    "    globpatt = BASEDIR + '/data/singles/summed_sorted/%s_%s.ctx' % (ID, pvec)\n",
    "    try:\n",
    "        counts, fname = vector_to_counts(globpatt)\n",
    "        rawcounts[pvec] = counts\n",
    "        rawcounts[pvec].attrs['FILE'] = fname\n",
    "    except (IOError) as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"Loaded data for {} vectors.\".format(len(rawcounts)))\n",
    "print(\"First element has shape {}\".format(next(iter(rawcounts.values())).shape))\n",
    "rawcounts.attrs['DETEFF'] = deteff\n",
    "rawcounts.attrs['DETEFF_FILE'] = deteff_file\n",
    "outfile.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Reference Data\n",
    "## Single Photon Data\n",
    "Beware: sometimes they are in the wrong order, i.e. singles_1 corresponds to the 5th column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_colcounts(col_nr):\n",
    "    globpatt = BASEDIR + '/data/singles/summed_sorted/'\n",
    "    globpatt += '%s_S%i_%.2i.ctx' % (ID, DIM, col_nr)\n",
    "    matches = glob(globpatt)\n",
    "    assert len(matches) == 1, \"It's actually {} for {}\"\\\n",
    "        .format(len(matches), col_nr)\n",
    "    summarydict = parse_ctx(matches[0])\n",
    "    return np.array([summarydict[det] for det in DETECTORS]), matches[0]\n",
    "    \n",
    "single_counts = f.create_group('SINGLE_COUNTS')\n",
    "for n in range(1, len(DETECTORS) + 1):\n",
    "    count, fname = get_colcounts(n)\n",
    "    # carefull! Sometimes they are the wrong way around!\n",
    "    index = n - 1\n",
    "    single_counts[str(index)] = count\n",
    "    single_counts[str(index)].attrs['FILE'] = fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# since they were taken at the same time\n",
    "single_counts.attrs['DETEFF'] = f['RAWCOUNTS'].attrs['DETEFF']\n",
    "single_counts.attrs['DETEFF_FILE'] = f['RAWCOUNTS'].attrs['DETEFF_FILE']\n",
    "outfile.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To check, we plot something proportional to the singles-transfer matrix. Note that we have to transpose counts since the single_counts[i] refer to columns of the transfer matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counts = np.array([single_counts[str(i)] for i in range(len(DETECTORS))],\n",
    "                 dtype=np.float64)\n",
    "counts *= single_counts.attrs['DETEFF']\n",
    "ax, *_ = imsshow([np.sqrt(counts).T])\n",
    "pl.colorbar(ax.images[0])\n",
    "pl.show()\n",
    "\n",
    "ax, *_ = imsshow([np.abs(target)])\n",
    "pl.colorbar(ax.images[0])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DETECTORS = f.attrs['DETECTORS']\n",
    "# Average total photon count (for normalization purposes)\n",
    "tmat_single = np.array([f['SINGLE_COUNTS'][str(i)] for i in range(len(DETECTORS))], dtype=float)\n",
    "deteff = f['SINGLE_COUNTS'].attrs['DETEFF']\n",
    "tmat_single = tmat_single * deteff\n",
    "# axis = 0 since we flip the tmat later\n",
    "tmat_single /= np.max(np.sum(tmat_single, axis=0))\n",
    "tmat_single = np.sqrt(tmat_single.T)\n",
    "f['TMAT_SINGLE'] = tmat_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Also, load the reconstruction using singles & dips (data missing, fill in in Sec. Dips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    recons = load_complex_array(BASEDIR + '/dip_reconstruction/%s_diprecon.dat' % ID)\n",
    "    f['DIP_RECONSTRUCTED'] = recons\n",
    "    outfile.flush()\n",
    "    imsshow([recons.real, recons.imag, np.abs(recons)])\n",
    "    pl.show()\n",
    "\n",
    "    imsshow([target.real, target.imag, np.abs(target)])\n",
    "    pl.show()\n",
    "except FileNotFoundError:\n",
    "    print(\"Dip reconstruction not found\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
